{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 0\n",
      "制作结束, 用时4.534870624542236秒\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "data_dir = r'C:\\python3\\test1223\\train\\train\\\\'\n",
    "batch_save_path = r'C:\\python3\\test1223\\train\\batch_files\\\\'\n",
    "\n",
    "# 创建batch文件存储的文件夹\n",
    "os.makedirs(batch_save_path, exist_ok=True)\n",
    "\n",
    "# 图片统一大小：100 * 100\n",
    "# 训练集 2000：10个batch文件，每个文件200张图片\n",
    "# 验证集 500\n",
    "\n",
    "# 进入图片数据的目录，读取图片信息\n",
    "all_data_files = os.listdir(os.path.join(data_dir,))\n",
    "\n",
    "# print(all_data_files)\n",
    "\n",
    "# 打算数据的顺序\n",
    "random.shuffle(all_data_files)\n",
    "\n",
    "all_train_files = all_data_files[:2000]\n",
    "all_test_files = all_data_files[2000:]\n",
    "\n",
    "train_data = []\n",
    "train_label = []\n",
    "train_filenames = []\n",
    "\n",
    "test_data = []\n",
    "test_label = []\n",
    "test_filenames = []\n",
    "\n",
    "# 训练集\n",
    "for each in all_train_files:\n",
    "    img = cv.imread(os.path.join(data_dir,each),1)\n",
    "    resized_img = cv.resize(img, (100,100))\n",
    "\n",
    "    img_data = np.array(resized_img)\n",
    "    train_data.append(img_data)\n",
    "    if 'cat' in each:\n",
    "        train_label.append(0)\n",
    "    elif 'dog' in each:\n",
    "        train_label.append(1)\n",
    "    else:\n",
    "        raise Exception('%s is wrong train file'%(each))\n",
    "    train_filenames.append(each)\n",
    "\n",
    "# 测试集\n",
    "for each in all_test_files:\n",
    "    img = cv.imread(os.path.join(data_dir,each), 1)\n",
    "    resized_img = cv.resize(img, (100,100))\n",
    "\n",
    "    img_data = np.array(resized_img)\n",
    "    test_data.append(img_data)\n",
    "    if 'cat' in each:\n",
    "        test_label.append(0)\n",
    "    elif 'dog' in each:\n",
    "        test_label.append(1)\n",
    "    else:\n",
    "        raise Exception('%s is wrong test file'%(each))\n",
    "    test_filenames.append(each)\n",
    "\n",
    "print(len(train_data), len(test_data))\n",
    "\n",
    "# 制作100个batch文件\n",
    "start = 0\n",
    "end = 200\n",
    "for num in range(1, 11):\n",
    "    batch_data = train_data[start: end]\n",
    "    batch_label = train_label[start: end]\n",
    "    batch_filenames = train_filenames[start: end]\n",
    "    batch_name = 'training batch {} of 15'.format(num)\n",
    "\n",
    "    all_data = {\n",
    "        'data':batch_data,\n",
    "        'label':batch_label,\n",
    "        'filenames':batch_filenames,\n",
    "        'name':batch_name\n",
    "    }\n",
    "\n",
    "    with open(os.path.join(batch_save_path, 'train_batch_{}'.format(num)), 'wb') as f:\n",
    "        pickle.dump(all_data, f)\n",
    "\n",
    "    start += 200\n",
    "    end += 200\n",
    "\n",
    "# 制作测试文件\n",
    "all_test_data = {\n",
    "    'data':test_data,\n",
    "    'label':test_label,\n",
    "    'filenames':test_filenames,\n",
    "    'name':'test batch 1 of 1'\n",
    "}\n",
    "\n",
    "with open(os.path.join(batch_save_path, 'test_batch'), 'wb') as f:\n",
    "    pickle.dump(all_test_data, f)\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "print('制作结束, 用时{}秒'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 100, 100, 3)\n",
      "(2000,)\n",
      "(1, 0)\n",
      "(0,)\n",
      "开始计算啦.\n",
      "step:100,loss:0.69831,acc:0.35,acc_mean:0.52475\n",
      "step:200,loss:0.67302,acc:0.625,acc_mean:0.54088\n",
      "step:300,loss:0.61187,acc:0.7,acc_mean:0.56875\n",
      "step:400,loss:0.56094,acc:0.7,acc_mean:0.59044\n",
      "step:500,loss:0.48523,acc:0.825,acc_mean:0.61335\n",
      "训练完成\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.reset_default_graph()\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "\n",
    "''' 全局参数 '''\n",
    "IMAGE_SIZE = 100\n",
    "LEARNING_RATE = 1e-3\n",
    "TRAIN_STEP = 500\n",
    "TRAIN_SIZE = 40\n",
    "TEST_STEP = 100\n",
    "TEST_SIZE = 10\n",
    "\n",
    "IS_TRAIN = True\n",
    "\n",
    "SAVE_PATH = 'C:/python3/test1223/train/model'\n",
    "\n",
    "data_dir = r'C:\\python3\\test1223\\train\\batch_files'\n",
    "pic_path = r'C:\\python3\\test1223\\test1'\n",
    "\n",
    "''''''\n",
    "\n",
    "def load_data(filename):\n",
    "    '''从batch文件中读取图片信息'''\n",
    "    with open(filename, 'rb') as f:\n",
    "        data = pickle.load(f, encoding='iso-8859-1')\n",
    "        return data['data'],data['label'],data['filenames']\n",
    "\n",
    "# 读取数据的类\n",
    "class InputData:\n",
    "    def __init__(self, filenames, need_shuffle):\n",
    "        all_data = []\n",
    "        all_labels = []\n",
    "        all_names = []\n",
    "        for file in filenames:\n",
    "            data, labels, filename = load_data(file)\n",
    "\n",
    "            all_data.append(data)\n",
    "            all_labels.append(labels)\n",
    "            all_names += filename\n",
    "\n",
    "        self._data = np.vstack(all_data)\n",
    "        self._labels = np.hstack(all_labels)\n",
    "        print(self._data.shape)\n",
    "        print(self._labels.shape)\n",
    "\n",
    "        self._filenames = all_names\n",
    "\n",
    "        self._num_examples = self._data.shape[0]\n",
    "        self._need_shuffle = need_shuffle\n",
    "        self._indicator = 0\n",
    "        if self._indicator:\n",
    "            self._shuffle_data()\n",
    "\n",
    "    def _shuffle_data(self):\n",
    "        # 把数据再混排\n",
    "        p = np.random.permutation(self._num_examples)\n",
    "        self._data = self._data[p]\n",
    "        self._labels = self._labels[p]\n",
    "\n",
    "    def next_batch(self, batch_size):\n",
    "        '''返回每一批次的数据'''\n",
    "        end_indicator = self._indicator + batch_size\n",
    "        if end_indicator > self._num_examples:\n",
    "            if self._need_shuffle:\n",
    "                self._shuffle_data()\n",
    "                self._indicator = 0\n",
    "                end_indicator = batch_size\n",
    "            else:\n",
    "                raise Exception('have no more examples')\n",
    "        if end_indicator > self._num_examples:\n",
    "            raise Exception('batch size is larger than all examples')\n",
    "        batch_data = self._data[self._indicator : end_indicator]\n",
    "        batch_labels = self._labels[self._indicator : end_indicator]\n",
    "        batch_filenames = self._filenames[self._indicator : end_indicator]\n",
    "        self._indicator = end_indicator\n",
    "        return batch_data, batch_labels, batch_filenames\n",
    "\n",
    "# 定义一个类\n",
    "class MyTensor:\n",
    "    def __init__(self):\n",
    "\n",
    "\n",
    "        # 载入训练集和测试集\n",
    "        train_filenames = [os.path.join(data_dir, 'train_batch_%d'%i) for i in range(1, 11)]\n",
    "        test_filenames = [os.path.join(data_dir, 'test_batch')]\n",
    "        self.batch_train_data = InputData(train_filenames, True)\n",
    "        self.batch_test_data = InputData(test_filenames, True)\n",
    "\n",
    "        pass\n",
    "\n",
    "    def flow(self):\n",
    "        self.x = tf.placeholder(tf.float32, [None, IMAGE_SIZE, IMAGE_SIZE, 3], 'input_data')\n",
    "        self.y = tf.placeholder(tf.int64, [None], 'output_data')\n",
    "        self.keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "        #self.x = self.x / 255.0  需不需要这一步？\n",
    "\n",
    "        # 图片输入网络中\n",
    "        fc = self.conv_net(self.x, self.keep_prob)\n",
    "\n",
    "        self.loss = tf.losses.sparse_softmax_cross_entropy(labels=self.y, logits=fc)\n",
    "        self.y_ = tf.nn.softmax(fc) # 计算每一类的概率\n",
    "        self.predict = tf.argmax(fc, 1)\n",
    "        self.acc = tf.reduce_mean(tf.cast(tf.equal(self.predict, self.y), tf.float32))\n",
    "\n",
    "        self.train_op = tf.train.AdamOptimizer(LEARNING_RATE).minimize(self.loss)\n",
    "        self.saver = tf.train.Saver(max_to_keep=1)\n",
    "\n",
    "        print('开始计算啦.')\n",
    "\n",
    "    # 训练\n",
    "    def myTrain(self):\n",
    "        acc_list = []\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            for i in range(TRAIN_STEP):\n",
    "                train_data, train_label, _ = self.batch_train_data.next_batch(TRAIN_SIZE)\n",
    "\n",
    "                eval_ops = [self.loss, self.acc, self.train_op]\n",
    "                eval_ops_results = sess.run(eval_ops, feed_dict={\n",
    "                    self.x:train_data,\n",
    "                    self.y:train_label,\n",
    "                    self.keep_prob:0.7\n",
    "                })\n",
    "                loss_val, train_acc = eval_ops_results[0:2]\n",
    "\n",
    "                acc_list.append(train_acc)\n",
    "                if (i+1) % 100 == 0:\n",
    "                    acc_mean = np.mean(acc_list)\n",
    "                    print('step:{0},loss:{1:.5},acc:{2:.5},acc_mean:{3:.5}'.format(\n",
    "                        i+1,loss_val,train_acc,acc_mean\n",
    "                    ))\n",
    "                if (i+1) % 1000 == 0:\n",
    "                    test_acc_list = []\n",
    "                    for j in range(TEST_STEP):\n",
    "                        test_data, test_label, _ = self.batch_test_data.next_batch(TRAIN_SIZE)\n",
    "                        acc_val = sess.run([self.acc],feed_dict={\n",
    "                            self.x:test_data,\n",
    "                            self.y:test_label,\n",
    "                            self.keep_prob:1.0\n",
    "                        })\n",
    "                        test_acc_list.append(acc_val)\n",
    "                    print('[Test ] step:{0}, mean_acc:{1:.5}'.format(\n",
    "                        i+1, np.mean(test_acc_list)\n",
    "                    ))\n",
    "            # 保存训练后的模型\n",
    "            os.makedirs(SAVE_PATH, exist_ok=True)\n",
    "            self.saver.save(sess, SAVE_PATH + 'my_model.ckpt')\n",
    "\n",
    "    def myTest(self):\n",
    "        with tf.Session() as sess:\n",
    "            model_file = tf.train.latest_checkpoint(r'C:\\python3\\test1223\\train\\model\\my_model.ckpt')\n",
    "            model = self.saver.restore(sess, save_path=r'C:\\python3\\test1223\\train\\model\\my_model.ckpt')\n",
    "            test_acc_list = []\n",
    "            predict_list = []\n",
    "            for j in range(TEST_STEP):\n",
    "                test_data, test_label, test_name = self.batch_test_data.next_batch(TEST_SIZE)\n",
    "                for each_data, each_label, each_name in zip(test_data, test_label, test_name):\n",
    "                    acc_val, y__, pre, test_img_data = sess.run(\n",
    "                        [self.acc, self.y_, self.predict, self.x],\n",
    "                        feed_dict={\n",
    "                            self.x:each_data.reshape(1, IMAGE_SIZE, IMAGE_SIZE, 3),\n",
    "                            self.y:each_label.reshape(1),\n",
    "                            self.keep_prob:1.0\n",
    "                        }\n",
    "                    )\n",
    "                    predict_list.append(pre[0])\n",
    "                    test_acc_list.append(acc_val)\n",
    "\n",
    "                    # 把测试结果显示出来\n",
    "                    self.compare_test(test_img_data, each_label, pre[0], y__[0], each_name)\n",
    "            print('[Test ] mean_acc:{0:.5}'.format(np.mean(test_acc_list)))\n",
    "\n",
    "    def compare_test(self, input_image_arr, input_label, output, probability, img_name):\n",
    "        classes = ['cat', 'dog']\n",
    "        if input_label == output:\n",
    "            result = '正确'\n",
    "        else:\n",
    "            result = '错误'\n",
    "        print('测试【{0}】,输入的label:{1}, 预测得是{2}:{3}的概率:{4:.5}, 输入的图片名称:{5}'.format(\n",
    "            result,input_label, output,classes[output], probability[output], img_name\n",
    "        ))\n",
    "\n",
    "    def conv_net(self, x, keep_prob):\n",
    "        conv1_1 = tf.layers.conv2d(x, 16, (3, 3), padding='same', activation=tf.nn.relu, name='conv1_1')\n",
    "        conv1_2 = tf.layers.conv2d(conv1_1, 16, (3, 3), padding='same', activation=tf.nn.relu, name='conv1_2')\n",
    "        pool1 = tf.layers.max_pooling2d(conv1_2, (2, 2), (2, 2), name='pool1')\n",
    "\n",
    "        conv2_1 = tf.layers.conv2d(pool1, 32, (3, 3), padding='same', activation=tf.nn.relu, name='conv2_1')\n",
    "        conv2_2 = tf.layers.conv2d(conv2_1, 32, (3, 3), padding='same', activation=tf.nn.relu, name='conv2_2')\n",
    "        pool2 = tf.layers.max_pooling2d(conv2_2, (2, 2), (2, 2), name='pool2')\n",
    "\n",
    "        conv3_1 = tf.layers.conv2d(pool2, 64, (3, 3), padding='same', activation=tf.nn.relu, name='conv3_1')\n",
    "        conv3_2 = tf.layers.conv2d(conv3_1, 64, (3, 3), padding='same', activation=tf.nn.relu, name='conv3_2')\n",
    "        pool3 = tf.layers.max_pooling2d(conv3_2, (2, 2), (2, 2), name='pool3')\n",
    "\n",
    "        conv4_1 = tf.layers.conv2d(pool3, 128, (3, 3), padding='same', activation=tf.nn.relu, name='conv4_1')\n",
    "        conv4_2 = tf.layers.conv2d(conv4_1, 128, (3, 3), padding='same', activation=tf.nn.relu, name='conv4_2')\n",
    "        pool4 = tf.layers.max_pooling2d(conv4_2, (2, 2), (2, 2), name='pool4')\n",
    "\n",
    "        flatten = tf.layers.flatten(pool4)  # 把网络展平，以输入到后面的全连接层\n",
    "\n",
    "        fc1 = tf.layers.dense(flatten, 512, tf.nn.relu)\n",
    "        fc1_dropout = tf.nn.dropout(fc1, keep_prob=keep_prob)\n",
    "        fc2 = tf.layers.dense(fc1, 256, tf.nn.relu)\n",
    "        fc2_dropout = tf.nn.dropout(fc2, keep_prob=keep_prob)\n",
    "        fc3 = tf.layers.dense(fc2, 2, None)  # 得到输出fc3\n",
    "\n",
    "        return fc3\n",
    "\n",
    "    def main(self):\n",
    "        self.flow()\n",
    "        if IS_TRAIN is True:\n",
    "            self.myTrain()\n",
    "        else:\n",
    "            self.myTest()\n",
    "\n",
    "    def final_classify(self):\n",
    "        all_test_files_dir = r'C:\\python3\\test1223\\test1'\n",
    "        all_test_filenames = os.listdir(all_test_files_dir)\n",
    "        if IS_TRAIN is False:\n",
    "            self.flow()\n",
    "            #self.classify()\n",
    "            with tf.Session() as sess:\n",
    "                model_file = tf.train.latest_checkpoint(r'C:\\python3\\test1223\\train\\model\\my_model.ckpt')\n",
    "                mpdel = self.saver.restore(sess,save_path=r'C:\\python3\\test1223\\train\\model\\my_model.ckpt')\n",
    "\n",
    "                predict_list = []\n",
    "                for each_filename in all_test_filenames:\n",
    "                    each_data = self.get_img_data(os.path.join(all_test_files_dir,each_filename))\n",
    "                    y__, pre, test_img_data = sess.run(\n",
    "                        [self.y_, self.predict, self.x],\n",
    "                        feed_dict={\n",
    "                            self.x:each_data.reshape(1, IMAGE_SIZE, IMAGE_SIZE, 3),\n",
    "                            self.keep_prob: 1.0\n",
    "                        }\n",
    "                    )\n",
    "                    predict_list.append(pre[0])\n",
    "                    self.classify(test_img_data, pre[0], y__[0], each_filename)\n",
    "\n",
    "        else:\n",
    "            print('now is training model...')\n",
    "\n",
    "    def classify(self, input_image_arr, output, probability, img_name):\n",
    "        classes = ['cat','dog']\n",
    "        single_image = input_image_arr[0] #* 255\n",
    "        if output == 0:\n",
    "            output_dir = 'cat/'\n",
    "        else:\n",
    "            output_dir = 'dog/'\n",
    "        os.makedirs(os.path.join(r'C:\\python3\\test1223\\train\\classiedResult', output_dir), exist_ok=True)\n",
    "        cv.imwrite(os.path.join(r'C:\\python3\\test1223\\train\\classiedResult',output_dir, img_name),single_image)\n",
    "        print('输入的图片名称:{0}，预测得有{1:5}的概率是{2}:{3}'.format(img_name,probability[output],output,classes[output]))\n",
    "\n",
    "    # 根据名称获取图片像素\n",
    "    def get_img_data(self,img_name):\n",
    "        img = cv.imread(img_name)\n",
    "        resized_img = cv.resize(img, (100, 100))\n",
    "        img_data = np.array(resized_img)\n",
    "\n",
    "        return img_data\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    mytensor = MyTensor()\n",
    "    mytensor.main()  # 用于训练或测试\n",
    "\n",
    "    #mytensor.final_classify() # 用于最后的分类\n",
    "\n",
    "    print('训练完成')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 100, 100, 3)\n",
      "(2000,)\n",
      "(1, 0)\n",
      "(0,)\n",
      "开始计算啦.\n",
      "INFO:tensorflow:Restoring parameters from C:\\python3\\test1223\\train\\modelmy_model.ckpt\n",
      "输入的图片名称:1.jpg，预测得有0.5548481345176697的概率是1:dog\n",
      "输入的图片名称:2.jpg，预测得有0.6710132360458374的概率是1:dog\n",
      "输入的图片名称:3.jpg，预测得有0.665400505065918的概率是0:cat\n",
      "输入的图片名称:4.jpg，预测得有0.996791422367096的概率是1:dog\n",
      "输入的图片名称:5.jpg，预测得有0.6798123121261597的概率是1:dog\n",
      "输入的图片名称:6.jpg，预测得有0.5863175988197327的概率是0:cat\n",
      "输入的图片名称:7.jpg，预测得有0.8613840937614441的概率是0:cat\n",
      "输入的图片名称:8.jpg，预测得有0.8550332188606262的概率是0:cat\n",
      "输入的图片名称:9.jpg，预测得有0.5721375942230225的概率是1:dog\n",
      "测试完成\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.reset_default_graph()\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "\n",
    "''' 全局参数 '''\n",
    "IMAGE_SIZE = 100\n",
    "LEARNING_RATE = 1e-3\n",
    "TRAIN_STEP = 500\n",
    "TRAIN_SIZE = 40\n",
    "TEST_STEP = 100\n",
    "TEST_SIZE = 10\n",
    "\n",
    "IS_TRAIN = False\n",
    "\n",
    "SAVE_PATH = 'C:/python3/test1223/train/model'\n",
    "\n",
    "data_dir = r'C:\\python3\\test1223\\train\\batch_files'\n",
    "pic_path = r'C:\\python3\\test1223\\test1'\n",
    "\n",
    "''''''\n",
    "\n",
    "def load_data(filename):\n",
    "    '''从batch文件中读取图片信息'''\n",
    "    with open(filename, 'rb') as f:\n",
    "        data = pickle.load(f, encoding='iso-8859-1')\n",
    "        return data['data'],data['label'],data['filenames']\n",
    "\n",
    "# 读取数据的类\n",
    "class InputData:\n",
    "    def __init__(self, filenames, need_shuffle):\n",
    "        all_data = []\n",
    "        all_labels = []\n",
    "        all_names = []\n",
    "        for file in filenames:\n",
    "            data, labels, filename = load_data(file)\n",
    "\n",
    "            all_data.append(data)\n",
    "            all_labels.append(labels)\n",
    "            all_names += filename\n",
    "\n",
    "        self._data = np.vstack(all_data)\n",
    "        self._labels = np.hstack(all_labels)\n",
    "        print(self._data.shape)\n",
    "        print(self._labels.shape)\n",
    "\n",
    "        self._filenames = all_names\n",
    "\n",
    "        self._num_examples = self._data.shape[0]\n",
    "        self._need_shuffle = need_shuffle\n",
    "        self._indicator = 0\n",
    "        if self._indicator:\n",
    "            self._shuffle_data()\n",
    "\n",
    "    def _shuffle_data(self):\n",
    "        # 把数据再混排\n",
    "        p = np.random.permutation(self._num_examples)\n",
    "        self._data = self._data[p]\n",
    "        self._labels = self._labels[p]\n",
    "\n",
    "    def next_batch(self, batch_size):\n",
    "        '''返回每一批次的数据'''\n",
    "        end_indicator = self._indicator + batch_size\n",
    "        if end_indicator > self._num_examples:\n",
    "            if self._need_shuffle:\n",
    "                self._shuffle_data()\n",
    "                self._indicator = 0\n",
    "                end_indicator = batch_size\n",
    "            else:\n",
    "                raise Exception('have no more examples')\n",
    "        if end_indicator > self._num_examples:\n",
    "            raise Exception('batch size is larger than all examples')\n",
    "        batch_data = self._data[self._indicator : end_indicator]\n",
    "        batch_labels = self._labels[self._indicator : end_indicator]\n",
    "        batch_filenames = self._filenames[self._indicator : end_indicator]\n",
    "        self._indicator = end_indicator\n",
    "        return batch_data, batch_labels, batch_filenames\n",
    "\n",
    "# 定义一个类\n",
    "class MyTensor:\n",
    "    def __init__(self):\n",
    "\n",
    "\n",
    "        # 载入训练集和测试集\n",
    "        train_filenames = [os.path.join(data_dir, 'train_batch_%d'%i) for i in range(1, 11)]\n",
    "        test_filenames = [os.path.join(data_dir, 'test_batch')]\n",
    "        self.batch_train_data = InputData(train_filenames, True)\n",
    "        self.batch_test_data = InputData(test_filenames, True)\n",
    "\n",
    "        pass\n",
    "\n",
    "    def flow(self):\n",
    "        self.x = tf.placeholder(tf.float32, [None, IMAGE_SIZE, IMAGE_SIZE, 3], 'input_data')\n",
    "        self.y = tf.placeholder(tf.int64, [None], 'output_data')\n",
    "        self.keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "        #self.x = self.x / 255.0  需不需要这一步？\n",
    "\n",
    "        # 图片输入网络中\n",
    "        fc = self.conv_net(self.x, self.keep_prob)\n",
    "\n",
    "        self.loss = tf.losses.sparse_softmax_cross_entropy(labels=self.y, logits=fc)\n",
    "        self.y_ = tf.nn.softmax(fc) # 计算每一类的概率\n",
    "        self.predict = tf.argmax(fc, 1)\n",
    "        self.acc = tf.reduce_mean(tf.cast(tf.equal(self.predict, self.y), tf.float32))\n",
    "\n",
    "        self.train_op = tf.train.AdamOptimizer(LEARNING_RATE).minimize(self.loss)\n",
    "        self.saver = tf.train.Saver(max_to_keep=1)\n",
    "\n",
    "        print('开始计算啦.')\n",
    "\n",
    "    # 训练\n",
    "    def myTrain(self):\n",
    "        acc_list = []\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            for i in range(TRAIN_STEP):\n",
    "                train_data, train_label, _ = self.batch_train_data.next_batch(TRAIN_SIZE)\n",
    "\n",
    "                eval_ops = [self.loss, self.acc, self.train_op]\n",
    "                eval_ops_results = sess.run(eval_ops, feed_dict={\n",
    "                    self.x:train_data,\n",
    "                    self.y:train_label,\n",
    "                    self.keep_prob:0.7\n",
    "                })\n",
    "                loss_val, train_acc = eval_ops_results[0:2]\n",
    "\n",
    "                acc_list.append(train_acc)\n",
    "                if (i+1) % 100 == 0:\n",
    "                    acc_mean = np.mean(acc_list)\n",
    "                    print('step:{0},loss:{1:.5},acc:{2:.5},acc_mean:{3:.5}'.format(\n",
    "                        i+1,loss_val,train_acc,acc_mean\n",
    "                    ))\n",
    "                if (i+1) % 1000 == 0:\n",
    "                    test_acc_list = []\n",
    "                    for j in range(TEST_STEP):\n",
    "                        test_data, test_label, _ = self.batch_test_data.next_batch(TRAIN_SIZE)\n",
    "                        acc_val = sess.run([self.acc],feed_dict={\n",
    "                            self.x:test_data,\n",
    "                            self.y:test_label,\n",
    "                            self.keep_prob:1.0\n",
    "                        })\n",
    "                        test_acc_list.append(acc_val)\n",
    "                    print('[Test ] step:{0}, mean_acc:{1:.5}'.format(\n",
    "                        i+1, np.mean(test_acc_list)\n",
    "                    ))\n",
    "            # 保存训练后的模型\n",
    "            os.makedirs(SAVE_PATH, exist_ok=True)\n",
    "            self.saver.save(sess, SAVE_PATH + 'my_model.ckpt')\n",
    "\n",
    "    def myTest(self):\n",
    "        with tf.Session() as sess:\n",
    "            model_file = tf.train.latest_checkpoint(r'C:\\python3\\test1223\\train\\modelmy_model.ckpt')\n",
    "            model = self.saver.restore(sess, save_path=r'C:\\python3\\test1223\\train\\modelmy_model.ckpt')\n",
    "            test_acc_list = []\n",
    "            predict_list = []\n",
    "            for j in range(TEST_STEP):\n",
    "                test_data, test_label, test_name = self.batch_test_data.next_batch(TEST_SIZE)\n",
    "                for each_data, each_label, each_name in zip(test_data, test_label, test_name):\n",
    "                    acc_val, y__, pre, test_img_data = sess.run(\n",
    "                        [self.acc, self.y_, self.predict, self.x],\n",
    "                        feed_dict={\n",
    "                            self.x:each_data.reshape(1, IMAGE_SIZE, IMAGE_SIZE, 3),\n",
    "                            self.y:each_label.reshape(1),\n",
    "                            self.keep_prob:1.0\n",
    "                        }\n",
    "                    )\n",
    "                    predict_list.append(pre[0])\n",
    "                    test_acc_list.append(acc_val)\n",
    "\n",
    "                    # 把测试结果显示出来\n",
    "                    self.compare_test(test_img_data, each_label, pre[0], y__[0], each_name)\n",
    "            print('[Test ] mean_acc:{0:.5}'.format(np.mean(test_acc_list)))\n",
    "\n",
    "    def compare_test(self, input_image_arr, input_label, output, probability, img_name):\n",
    "        classes = ['cat', 'dog']\n",
    "        if input_label == output:\n",
    "            result = '正确'\n",
    "        else:\n",
    "            result = '错误'\n",
    "        print('测试【{0}】,输入的label:{1}, 预测得是{2}:{3}的概率:{4:.5}, 输入的图片名称:{5}'.format(\n",
    "            result,input_label, output,classes[output], probability[output], img_name\n",
    "        ))\n",
    "\n",
    "    def conv_net(self, x, keep_prob):\n",
    "        conv1_1 = tf.layers.conv2d(x, 16, (3, 3), padding='same', activation=tf.nn.relu, name='conv1_1')\n",
    "        conv1_2 = tf.layers.conv2d(conv1_1, 16, (3, 3), padding='same', activation=tf.nn.relu, name='conv1_2')\n",
    "        pool1 = tf.layers.max_pooling2d(conv1_2, (2, 2), (2, 2), name='pool1')\n",
    "\n",
    "        conv2_1 = tf.layers.conv2d(pool1, 32, (3, 3), padding='same', activation=tf.nn.relu, name='conv2_1')\n",
    "        conv2_2 = tf.layers.conv2d(conv2_1, 32, (3, 3), padding='same', activation=tf.nn.relu, name='conv2_2')\n",
    "        pool2 = tf.layers.max_pooling2d(conv2_2, (2, 2), (2, 2), name='pool2')\n",
    "\n",
    "        conv3_1 = tf.layers.conv2d(pool2, 64, (3, 3), padding='same', activation=tf.nn.relu, name='conv3_1')\n",
    "        conv3_2 = tf.layers.conv2d(conv3_1, 64, (3, 3), padding='same', activation=tf.nn.relu, name='conv3_2')\n",
    "        pool3 = tf.layers.max_pooling2d(conv3_2, (2, 2), (2, 2), name='pool3')\n",
    "\n",
    "        conv4_1 = tf.layers.conv2d(pool3, 128, (3, 3), padding='same', activation=tf.nn.relu, name='conv4_1')\n",
    "        conv4_2 = tf.layers.conv2d(conv4_1, 128, (3, 3), padding='same', activation=tf.nn.relu, name='conv4_2')\n",
    "        pool4 = tf.layers.max_pooling2d(conv4_2, (2, 2), (2, 2), name='pool4')\n",
    "\n",
    "        flatten = tf.layers.flatten(pool4)  # 把网络展平，以输入到后面的全连接层\n",
    "\n",
    "        fc1 = tf.layers.dense(flatten, 512, tf.nn.relu)\n",
    "        fc1_dropout = tf.nn.dropout(fc1, keep_prob=keep_prob)\n",
    "        fc2 = tf.layers.dense(fc1, 256, tf.nn.relu)\n",
    "        fc2_dropout = tf.nn.dropout(fc2, keep_prob=keep_prob)\n",
    "        fc3 = tf.layers.dense(fc2, 2, None)  # 得到输出fc3\n",
    "\n",
    "        return fc3\n",
    "\n",
    "    def main(self):\n",
    "        self.flow()\n",
    "        if IS_TRAIN is True:\n",
    "            self.myTrain()\n",
    "        else:\n",
    "            self.myTest()\n",
    "\n",
    "    def final_classify(self):\n",
    "        all_test_files_dir = r'C:\\python3\\test1223\\test1'\n",
    "        all_test_filenames = os.listdir(all_test_files_dir)\n",
    "        if IS_TRAIN is False:\n",
    "            self.flow()\n",
    "            #self.classify()\n",
    "            with tf.Session() as sess:\n",
    "                model_file = tf.train.latest_checkpoint(r'C:\\python3\\test1223\\train\\modelmy_model.ckpt')\n",
    "                mpdel = self.saver.restore(sess,save_path=r'C:\\python3\\test1223\\train\\modelmy_model.ckpt')\n",
    "\n",
    "                predict_list = []\n",
    "                for each_filename in all_test_filenames:\n",
    "                    each_data = self.get_img_data(os.path.join(all_test_files_dir,each_filename))\n",
    "                    y__, pre, test_img_data = sess.run(\n",
    "                        [self.y_, self.predict, self.x],\n",
    "                        feed_dict={\n",
    "                            self.x:each_data.reshape(1, IMAGE_SIZE, IMAGE_SIZE, 3),\n",
    "                            self.keep_prob: 1.0\n",
    "                        }\n",
    "                    )\n",
    "                    predict_list.append(pre[0])\n",
    "                    self.classify(test_img_data, pre[0], y__[0], each_filename)\n",
    "\n",
    "        else:\n",
    "            print('now is training model...')\n",
    "\n",
    "    def classify(self, input_image_arr, output, probability, img_name):\n",
    "        classes = ['cat','dog']\n",
    "        single_image = input_image_arr[0] #* 255\n",
    "        if output == 0:\n",
    "            output_dir = 'cat/'\n",
    "        else:\n",
    "            output_dir = 'dog/'\n",
    "        os.makedirs(os.path.join(r'C:\\python3\\test1223\\train\\classiedResult', output_dir), exist_ok=True)\n",
    "        cv.imwrite(os.path.join(r'C:\\python3\\test1223\\train\\classiedResult',output_dir, img_name),single_image)\n",
    "        print('输入的图片名称:{0}，预测得有{1:5}的概率是{2}:{3}'.format(img_name,probability[output],output,classes[output]))\n",
    "\n",
    "    # 根据名称获取图片像素\n",
    "    def get_img_data(self,img_name):\n",
    "        img = cv.imread(img_name)\n",
    "        resized_img = cv.resize(img, (100, 100))\n",
    "        img_data = np.array(resized_img)\n",
    "\n",
    "        return img_data\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    mytensor = MyTensor()\n",
    "    #mytensor.main()  # 用于训练或测试\n",
    "\n",
    "    mytensor.final_classify() # 用于最后的分类\n",
    "\n",
    "    print('测试完成')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
